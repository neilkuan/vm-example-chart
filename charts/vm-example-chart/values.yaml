grafana:
  enabled: true
  fullnameOverride: "grafana"
  testFramework:
    enabled: false
  adminUser: admin
  adminPassword: "vm-example-chart"
  service:
    port: 3000
  image:
    tag: 11.1.2
  plugins:
  - https://github.com/VictoriaMetrics/victorialogs-datasource/releases/download/v0.4.0/victorialogs-datasource-v0.4.0.zip;victorialogs-datasource
  grafana.ini:
    plugins:
      enable_alpha: true
      allow_loading_unsigned_plugins: victorialogs-datasource
  persistence:
    enabled: true
    size: 100Mi
  alerting:
    contactpoints.yaml:
      secret:
        contactPoints: []
  datasources:
    datasources.yaml:
      apiVersion: 1
      datasources:
      - name: VictoriaLogs
        type: victorialogs-datasource
        uid: VictoriaLogs
        access: proxy
        url: http://victoria-logs-single:9428
        editable: true
      - name: vm-select-0
        type: prometheus
        uid: victoria_metrics_0
        access: proxy
        url: http://vmselect:8481/select/0/prometheus
        editable: true
  # dashboardProviders:
  #  dashboardproviders.yaml:
  #    apiVersion: 1
  #    providers:
  #    - name: 'default'
  #      orgId: 1
  #      folder: ''
  #      type: file
  #      disableDeletion: false
  #      editable: true
  #      options:
  #        path: /var/lib/grafana/dashboards/default
  # dashboards:
  #   default:
  #     events:
  #       url: https://raw.githubusercontent.com/neilkuan/k8s-event-to-loki-grafana/main/dashboard.json

victoria-logs-single:
  enabled: true
  global:
    victoriaLogs:
      server:
        fullnameOverride: victoria-logs-single
  fluent-bit:
    enabled: true
    fullnameOverride: fluent-bit
    testFramework:
      enabled: false
    daemonSetVolumes:
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
  
    daemonSetVolumeMounts:
      - name: varlog
        mountPath: /var/log
      - name: varlibdockercontainers
        mountPath: /var/lib/docker/containers
        readOnly: true
    config:
      outputs: |
        [OUTPUT]
            Name http
            Match kube.*
            Host victoria-logs-single
            port 9428
            compress gzip
            uri /insert/jsonline?_stream_fields=stream,kubernetes_pod_name,kubernetes_container_name&_msg_field=log&_time_field=date
            format json_lines
            json_date_format iso8601
            header AccountID 0
            header ProjectID 0
      filters: |
        [FILTER]
            Name kubernetes
            Match kube.*
            Merge_Log On
            Keep_Log On
            K8S-Logging.Parser On
            K8S-Logging.Exclude On
        [FILTER]
            Name                nest
            Match               *
            Wildcard            pod_name
            Operation lift
            Nested_under kubernetes
            Add_prefix   kubernetes_

victoria-metrics-agent:
  enabled: true
  fullnameOverride: "victoria-metrics-agent"
  replicaCount: 1
  # ref: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/
  deployment:
    enabled: false
  statefulset:
    enabled: true
    clusterMode: true
    replicationFactor: 1
    updateStrategy:
      type: RollingUpdate
  remoteWriteUrls:
    - http://vminsert:8480/insert/0/prometheus
  config:
    global:
      scrape_interval: 10s
      external_labels:
          datacenter: local-cluster

victoria-metrics-cluster:
  enabled: true
  vmselect:
    enabled: true
    fullnameOverride: "vmselect"
  vminsert:
    enabled: true
    fullnameOverride: "vminsert"
    extraArgs:
      envflag.enable: "true"
      envflag.prefix: VM_
      loggerFormat: json
      maxLabelsPerTimeseries: 60
  vmstorage:
    enabled: true
    fullnameOverride: "vmstorage"
    retentionPeriod: 1
    replicaCount: 1

prometheus-node-exporter:
  enabled: true
  fullnameOverride: "node-exporter"
  service:
    annotations:
      prometheus.io/scrape: "true"
      prometheus.io/port: "9100"
      prometheus.io/path: "/metrics"

kube-state-metrics:
  enabled: true
  fullnameOverride: "kube-state-metrics"
  service:
    annotations:
      prometheus.io/scrape: "true"
      prometheus.io/port: "8080"
      prometheus.io/path: "/metrics"

telegraf:
  enabled: false
  fullnameOverride: "telegraf"

beyla:
  enabled: true
  fullnameOverride: "beyla"
  image:
    tag: 2.0.5
  config:
    data:
      log_level: INFO
      otel_metrics_export:
        features:
          - application
          - application_process
          - network
        endpoint: http://otel-collector-deployment:4317
        protocol: grpc
      network:
        enable: true
      # trace_printer: json # default disable, enable for debug
      attributes:
        kubernetes:
          enable: true
        select:
          process_cpu_time*:
            exclude: ["process*"]
          traces:
            include:
            - db.query.text
  nodeSelector:
    kubernetes.io/os: linux
  tolerations:
  - effect: NoSchedule
    operator: Exists
  env:
    BEYLA_BPF_TRACK_REQUEST_HEADERS: "true"
    BEYLA_BPF_ENABLE_CONTEXT_PROPAGATION: "false"
    BEYLA_PROMETHEUS_PORT: "0"
    BEYLA_KUBE_CLUSTER_NAME: "orbstack"
opentelemetry-collector:
  enabled: true
  fullnameOverride: "otel-collector-deployment"
  mode: "deployment"
  image:
    repository: "otel/opentelemetry-collector-k8s"
  command:
    name: "otelcol-k8s"
  resources:
    limits:
      memory: 512Mi
    requests:
      memory: 128Mi
  config:
    exporters:
      debug:
        verbosity: basic
      otlphttp:
        compression: gzip
        encoding: proto
        endpoint: http://vminsert:8480/insert/0/opentelemetry
    extensions:
      # The health_check extension is mandatory for this chart.
      # Without the health_check extension the collector will fail the readiness and liveliness probes.
      # The health_check extension can be modified, but should never be removed.
      health_check:
        endpoint: ${env:MY_POD_IP}:13133
    processors:
      batch: {}
      # Default memory limiter configuration for the collector based on k8s resource limits.
      memory_limiter:
        # check_interval is the time between measurements of memory usage.
        check_interval: 5s
        # By default limit_mib is set to 80% of ".Values.resources.limits.memory"
        limit_percentage: 80
        # By default spike_limit_mib is set to 25% of ".Values.resources.limits.memory"
        spike_limit_percentage: 25
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: ${env:MY_POD_IP}:4317
          http:
            endpoint: ${env:MY_POD_IP}:4318
    service:
      telemetry:
        metrics:
          address: ${env:MY_POD_IP}:8888
      extensions:
        - health_check
      pipelines:
        metrics:
          receivers: [otlp, prometheus]
          processors: [memory_limiter, batch]
          exporters: [otlphttp]